{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOaYcyBeWpG1",
        "colab_type": "text"
      },
      "source": [
        "Download and Extract the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns3RiMOkEpXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiBWFZWyUOvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1bde1e3c-9972-49b7-ace6-87d37d9d741f"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"akmalhussain72\"\n",
        "\n",
        "os.environ['KAGGLE_KEY'] =\"0497cdcb67183b7a904f124f92eda0c1\"\n",
        "\n",
        "!kaggle datasets download -d fpeccia/weed-detection-in-soybean-crops"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading weed-detection-in-soybean-crops.zip to /content\n",
            "100% 2.36G/2.37G [00:22<00:00, 75.9MB/s]\n",
            "100% 2.37G/2.37G [00:22<00:00, 114MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOHv18ujWm5U",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7k9rZY2UnSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc9ab5b5-a2f2-4070-ae0a-4e92983ca52b"
      },
      "source": [
        "\n",
        " \n",
        "#ZipFile is a class of zipfile module for reading and writing zip files\n",
        "from zipfile import ZipFile\n",
        "#filename = zip file path \n",
        "file_name = \"/content/weed-detection-in-soybean-crops.zip\"\n",
        "#to extract the zip file\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqXOuMYQY1mp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca42d5b2-fa31-4616-8697-8f8b373807c9"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6DPnaKDW1UJ",
        "colab_type": "text"
      },
      "source": [
        "Making The Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6NzIwq5U1Tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/train_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGYjEKCkU5hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/train_data/broadleaf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QjOCu7qU9WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/train_data/grass\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucfsVRfqVFMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/train_data/soil\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeY8xItgVJl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/train_data/soybean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz_OxaJEVOZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/test_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAuD8LioVSMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/test_data/broadleaf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCkcqm-jVW6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/test_data/grass\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB8_PEQ4VaJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/test_data/soil\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXU_eyhpVdlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/test_data/soybean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut1lRoErVj8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cXH4_xaVp9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import copyfile \n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqHG8CBWW7A2",
        "colab_type": "text"
      },
      "source": [
        "Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik-oe7IJVyjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(source,training,testing,split_size):\n",
        "  files = []\n",
        "  for filename in os.listdir(source):\n",
        "    file = source+filename\n",
        "    files.append(filename)\n",
        "    training_length = int(len(files)*split_size)\n",
        "    shuffled_set = random.sample(files,len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[training_length:]\n",
        "  for filename in training_set:\n",
        "    this_file = source+filename \n",
        "    destination = training+filename \n",
        "    copyfile(this_file,destination)        \n",
        "  for filename in testing_set:\n",
        "    this_file = source+filename \n",
        "    destination = testing+filename \n",
        "    copyfile(this_file,destination)\n",
        "# splitt data function and size is o.8\n",
        "split_data(\"/content/dataset/broadleaf/\",\"/content/train_data/broadleaf/\",\"/content/test_data/broadleaf/\",0.8)\n",
        "split_data(\"/content/dataset/grass/\",\"/content/train_data/grass/\",\"/content/test_data/grass/\",0.8)\n",
        "split_data(\"/content/dataset/soil/\",\"/content/train_data/soil/\",\"/content/test_data/soil/\",0.8)\n",
        "split_data(\"/content/dataset/soybean/\",\"/content/train_data/soybean/\",\"/content/test_data/soybean/\",0.8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVPGF-y9oyGZ",
        "colab_type": "text"
      },
      "source": [
        "Data splitted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITQFjap5o6tc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0646f7d-9412-44b2-f783-c4dc9a16cbde"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxOzQsjtpH3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/content/train_data'\n",
        "test_dir = '/content/test_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO5eL6RtpPXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen_obj = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "test_gen_obj = ImageDataGenerator(rescale = 1.0/255.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdrehLmcpVw9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88c4d856-8899-4fc7-afd6-be677e893381"
      },
      "source": [
        "train_gen = train_gen_obj.flow_from_directory(train_dir, batch_size = 128, target_size = (150, 150), class_mode = 'categorical')\n",
        "test_gen = test_gen_obj.flow_from_directory(test_dir, batch_size = 64, target_size = (150, 150), class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12267 images belonging to 4 classes.\n",
            "Found 3069 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1xopA99phME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KQdYk5RpoSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.4), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'), \n",
        "    tf.keras.layers.Dense(4, activation='softmax')  \n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik3yqzPIp1M4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "616cfa34-3058-4f80-cdd9-af2c4133d646"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               2367616   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 2,391,716\n",
            "Trainable params: 2,391,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYYeUNbfE4yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model. \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFTjZeG9E6ER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the Model\n",
        "history = model.fit_generator(train_gen,\n",
        "                              validation_data = test_gen,\n",
        "                              epochs = 10, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ome9iYwFEJi",
        "colab_type": "text"
      },
      "source": [
        "Epoch 1/10\n",
        "192/192 [==============================] - 67s 348ms/step - loss: 0.5246 - acc: 0.7944 - val_loss: 0.4456 - val_acc: 0.8804\n",
        "Epoch 2/10\n",
        "192/192 [==============================] - 60s 313ms/step - loss: 0.3010 - acc: 0.8885 - val_loss: 0.5729 - val_acc: 0.8521\n",
        "Epoch 3/10\n",
        "192/192 [==============================] - 60s 314ms/step - loss: 0.2345 - acc: 0.9145 - val_loss: 0.2687 - val_acc: 0.9176\n",
        "Epoch 4/10\n",
        "192/192 [==============================] - 61s 316ms/step - loss: 0.1661 - acc: 0.9398 - val_loss: 0.2689 - val_acc: 0.9312\n",
        "Epoch 5/10\n",
        "192/192 [==============================] - 60s 314ms/step - loss: 0.1296 - acc: 0.9506 - val_loss: 0.1752 - val_acc: 0.9303\n",
        "Epoch 6/10\n",
        "192/192 [==============================] - 60s 315ms/step - loss: 0.0994 - acc: 0.9647 - val_loss: 0.0819 - val_acc: 0.9309\n",
        "Epoch 7/10\n",
        "192/192 [==============================] - 60s 314ms/step - loss: 0.0682 - acc: 0.9764 - val_loss: 0.4128 - val_acc: 0.9407\n",
        "Epoch 8/10\n",
        "192/192 [==============================] - 60s 310ms/step - loss: 0.0512 - acc: 0.9824 - val_loss: 0.5732 - val_acc: 0.9339\n",
        "Epoch 9/10\n",
        "192/192 [==============================] - 60s 313ms/step - loss: 0.0401 - acc: 0.9857 - val_loss: 0.3409 - val_acc: 0.9185\n",
        "Epoch 10/10\n",
        "192/192 [==============================] - 61s 317ms/step - loss: 0.0291 - acc: 0.9916 - val_loss: 0.0319 - val_acc: 0.9482"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gff_MRbMFUDJ",
        "colab_type": "text"
      },
      "source": [
        "**Plot for accuracy and loss on both training and validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQzY-2ToFG3l",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcQT5iRGFvIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "#epochs = 5\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fUneT0rG8QL",
        "colab_type": "text"
      },
      "source": [
        "Checking model with drone captured images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP1rTMBCG9Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "#directory to store the images taken by drone\n",
        "os.mkdir(\"testing_outputs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCHkH6cIHApq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source = \"/content/testing_outputs/\"\n",
        "from skimage.transform import resize\n",
        "from skimage.transform import resize\n",
        "classification=['broad','grass','soil','soya']\n",
        "for filename in os.listdir(source):\n",
        "  #changing path to current directory\n",
        "  os.chdir(source)\n",
        "  #extracting the path\n",
        "  this_file = source+filename \n",
        "  #extracting the image name\n",
        "  this_file = this_file[25:]\n",
        "  #storing image to new_image\n",
        "  new_image=plt.imread(this_file)\n",
        "  print(this_file)\n",
        "  \n",
        "  #to resize the image to match model input size\n",
        "  resized_image = resize(new_image, (150,150,3))\n",
        "  #to predict the input image using our model\n",
        "  predictions = model.predict(np.array( [resized_image] ))\n",
        "  #list_index defines 0 for broadleaf, 1 for grass,2 for soil,3 for soybean\n",
        "  list_index = [0,1,2,3]\n",
        "  #storing predicted output by the model to x\n",
        "  x = predictions\n",
        "  # arranging the list in such a way that highest probability list index comes to first position of the list\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      if x[0][list_index[i]] > x[0][list_index[j]]:\n",
        "        temp = list_index[i]\n",
        "        list_index[i] = list_index[j]\n",
        "        list_index[j] = temp\n",
        "  #Show the sorted labels in order from highest probability to lowest\n",
        "  print(list_index,end='\\t')\n",
        "  print(classification[list_index[0]],end='\\t')\n",
        "  if(classification[list_index[0]]=='broad'):\n",
        "    print('weed',end='\\n')\n",
        "    \n",
        "    print('...........')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7eVBriRHW_t",
        "colab_type": "text"
      },
      "source": [
        "102.tif\n",
        "[0, 1, 3, 2]\tbroad\tweed\n",
        "...........\n",
        "\n",
        "1018.tif\n",
        "[2, 1, 0, 3]\tsoil\tnon weed\n",
        "...........\n",
        "\n",
        "1032.tif\n",
        "[3, 1, 0, 2]\tsoya\tnon weed\n",
        "...........\n",
        "\n",
        "101.tif\n",
        "[3, 1, 0, 2]\tsoya\tnon weed\n",
        "...........\n",
        "\n",
        "106.tif\n",
        "[0, 1, 3, 2]\tbroad\tweed\n",
        "...........\n",
        "\n",
        "1.tif\n",
        "[0, 1, 3, 2]\tbroad\tweed\n",
        "...........\n",
        "\n",
        "3565.tif\n",
        "[3, 1, 0, 2]\tsoya\tnon weed\n",
        "...........\n",
        "\n",
        "100.tif\n",
        "[0, 1, 3, 2]\tbroad\tweed\n",
        "...........\n",
        "\n",
        "4327.tif\n",
        "[3, 1, 0, 2]\tsoya\tnon weed\n",
        "...........\n",
        "\n",
        "1025.tif\n",
        "[0, 1, 3, 2]\tbroad\tweed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuGi8stGHlVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUKH5Hg4Hoh6",
        "colab_type": "text"
      },
      "source": [
        "Using \"VGG16\" model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMtkUlLFHqzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4wfZwEGHu18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building vgg16 model\n",
        "model_vgg16 = tf.keras.applications.VGG16(include_top=False, input_shape=(150,150, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL0jqJUmH2_l",
        "colab_type": "text"
      },
      "source": [
        "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "58892288/58889256 [==============================] - 1s 0us/step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwz9UNVsH4am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model_vgg16.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SGnTe-1H8Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#activation function\n",
        "leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.3)\n",
        "leaky_relu.__name__ = 'leaky_relu'\n",
        "#flatten the layers\n",
        "flat1 = tf.keras.layers.Flatten()(model_vgg16.layers[-1].output)\n",
        "#256 neuron layers\n",
        "class1 = tf.keras.layers.Dense(256, activation=leaky_relu)(flat1)\n",
        "#using dropouts\n",
        "drop1 = tf.keras.layers.Dropout(0.5)(class1)\n",
        "class2 = tf.keras.layers.Dense(256, activation=leaky_relu)(drop1)\n",
        "drop2 = tf.keras.layers.Dropout(0.5)(class2)\n",
        "#using softmax function \n",
        "output = tf.keras.layers.Dense(4, activation='softmax')(drop2)\n",
        "\n",
        "model_vgg16 = tf.keras.models.Model(inputs=model_vgg16.inputs, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U9oE5ooH_5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model summary\n",
        "model_vgg16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boTXqrbsINxV",
        "colab_type": "text"
      },
      "source": [
        "Model: \"model\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
        "_________________________________________________________________\n",
        "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
        "_________________________________________________________________\n",
        "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
        "_________________________________________________________________\n",
        "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
        "_________________________________________________________________\n",
        "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
        "_________________________________________________________________\n",
        "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
        "_________________________________________________________________\n",
        "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
        "_________________________________________________________________\n",
        "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
        "_________________________________________________________________\n",
        "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
        "_________________________________________________________________\n",
        "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
        "_________________________________________________________________\n",
        "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
        "_________________________________________________________________\n",
        "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
        "_________________________________________________________________\n",
        "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 8192)              0         \n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 256)               2097408   \n",
        "_________________________________________________________________\n",
        "dropout (Dropout)            (None, 256)               0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 256)               65792     \n",
        "_________________________________________________________________\n",
        "dropout_1 (Dropout)          (None, 256)               0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 4)                 1028      \n",
        "=================================================================\n",
        "Total params: 16,878,916\n",
        "Trainable params: 2,164,228\n",
        "Non-trainable params: 14,714,688"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caPgmoCzIPNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model\n",
        "model_vgg16.compile(optimizer=keras.optimizers.Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at_Kn5psIZJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "history = model_vgg16.fit(train_gen, epochs=10,\n",
        "                          validation_data=test_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHi5kT78IfFM",
        "colab_type": "text"
      },
      "source": [
        "Epoch 1/10\n",
        "192/192 [==============================] - 82s 427ms/step - loss: 0.3048 - accuracy: 0.9026 - val_loss: 0.0850 - val_accuracy: 0.9723\n",
        "Epoch 2/10\n",
        "192/192 [==============================] - 75s 393ms/step - loss: 0.1191 - accuracy: 0.9633 - val_loss: 0.0482 - val_accuracy: 0.9824\n",
        "Epoch 3/10\n",
        "192/192 [==============================] - 76s 394ms/step - loss: 0.1008 - accuracy: 0.9712 - val_loss: 0.0477 - val_accuracy: 0.9850\n",
        "Epoch 4/10\n",
        "192/192 [==============================] - 76s 395ms/step - loss: 0.0798 - accuracy: 0.9769 - val_loss: 0.0640 - val_accuracy: 0.9827\n",
        "Epoch 5/10\n",
        "192/192 [==============================] - 76s 395ms/step - loss: 0.0782 - accuracy: 0.9775 - val_loss: 0.1019 - val_accuracy: 0.9694\n",
        "Epoch 6/10\n",
        "192/192 [==============================] - 76s 394ms/step - loss: 0.0548 - accuracy: 0.9845 - val_loss: 0.0467 - val_accuracy: 0.9857\n",
        "Epoch 7/10\n",
        "192/192 [==============================] - 76s 395ms/step - loss: 0.0416 - accuracy: 0.9879 - val_loss: 0.0751 - val_accuracy: 0.9808\n",
        "Epoch 8/10\n",
        "192/192 [==============================] - 76s 396ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.0676 - val_accuracy: 0.9827\n",
        "Epoch 9/10\n",
        "192/192 [==============================] - 76s 397ms/step - loss: 0.0666 - accuracy: 0.9830 - val_loss: 0.0675 - val_accuracy: 0.9824\n",
        "Epoch 10/10\n",
        "192/192 [==============================] - 75s 393ms/step - loss: 0.0473 - accuracy: 0.9861 - val_loss: 0.0469 - val_accuracy: 0.9863"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSVA_dfiIh7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JTftu_mImH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-WB18K9Iq04",
        "colab_type": "text"
      },
      "source": [
        "Plot for accuracy and loss on both training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-h4SRAZIr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KQ_FGbvIyv9",
        "colab_type": "text"
      },
      "source": [
        "Checking model with drone captured images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZvoNS_FIz2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "#directory to store the images taken by drone\n",
        "os.mkdir(\"testing_outputs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fST_fs5I26j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source = \"/content/testing_outputs/\"\n",
        "from skimage.transform import resize\n",
        "from skimage.transform import resize\n",
        "classification=['broad','grass','soil','soya']\n",
        "for filename in os.listdir(source):\n",
        "  #changing path to current directory\n",
        "  os.chdir(source)\n",
        "  #extracting the path\n",
        "  this_file = source+filename \n",
        "  #extracting the image name\n",
        "  this_file = this_file[25:]\n",
        "  #storing image to new_image\n",
        "  new_image=plt.imread(this_file)\n",
        "  print(this_file)\n",
        "  \n",
        "  #to resize the image to match model input size\n",
        "  resized_image = resize(new_image, (150,150,3))\n",
        "  #to predict the input image using our model\n",
        "  predictions = model_vgg16.predict(np.array( [resized_image] ))\n",
        "  #list_index defines 0 for broadleaf, 1 for grass,2 for soil,3 for soybean\n",
        "  list_index = [0,1,2,3]\n",
        "  #storing predicted output by the model to x\n",
        "  x = predictions\n",
        "  # arranging the list in such a way that highest probability list index comes to first position of the list\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      if x[0][list_index[i]] > x[0][list_index[j]]:\n",
        "        temp = list_index[i]\n",
        "        list_index[i] = list_index[j]\n",
        "        list_index[j] = temp\n",
        "  #Show the sorted labels in order from highest probability to lowest\n",
        "  print(list_index,end='\\t')\n",
        "  print(classification[list_index[0]],end='\\t')\n",
        "  if(classification[list_index[0]]=='broad'):\n",
        "    print('weed',end='\\n')\n",
        "    \n",
        "    print('...................')\n",
        "    \n",
        "\n",
        "  else:\n",
        "    print(\"non weed\",end='\\n')\n",
        "    print('....................')  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIzGX16XJJSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEwhIrXQJKfZ",
        "colab_type": "text"
      },
      "source": [
        "102.tif\n",
        "[0, 3, 1, 2]\tbroad\tweed\n",
        "\n",
        "\n",
        "1018.tif\n",
        "[2, 0, 3, 1]\tsoil\tnon weed\n",
        "\n",
        "\n",
        "1032.tif\n",
        "[3, 0, 1, 2]\tsoya\tnon weed\n",
        "\n",
        "\n",
        "101.tif\n",
        "[3, 0, 2, 1]\tsoya\tnon weed\n",
        "\n",
        "\n",
        "106.tif\n",
        "[0, 3, 1, 2]\tbroad\tweed\n",
        "\n",
        "\n",
        "1.tif\n",
        "[0, 3, 1, 2]\tbroad\tweed\n",
        "\n",
        "\n",
        "3565.tif\n",
        "[3, 0, 1, 2]\tsoya\tnon weed\n",
        "\n",
        "\n",
        "100.tif\n",
        "[0, 3, 1, 2]\tbroad\tweed\n",
        "\n",
        "\n",
        "4327.tif\n",
        "[3, 1, 0, 2]\tsoya\tnon weed\n",
        "\n",
        "\n",
        "1025.tif\n",
        "[0, 3, 1, 2]\tbroad\tweed"
      ]
    }
  ]
}